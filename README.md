# vLLM Lab

## Overview

This repository contains Terraform configurations for deploying [vLLM](https://github.com/vllm-project/vllm) on Kubernetes clusters across multiple cloud providers, including Civo, Oracle Cloud (OCI), AWS, GCP, and Azure. This setup is based on the [llmcache vllm production-stack](https://github.com/llmcache/vllm-production-stack) project.

## Supported Platforms

- **Civo Kubernetes**
- **Oracle Cloud (OCI) OKE**
- **Amazon Web Services (AWS) EKS**
- **Google Cloud Platform (GCP) GKE**
- **Microsoft Azure AKS**

## Deployment Guide

### Prerequisites

Ensure you have the following installed:

- [Terraform](https://developer.hashicorp.com/terraform/downloads)
- [kubectl](https://kubernetes.io/docs/tasks/tools/)
- Cloud CLI tools:
  - [Civo CLI](https://www.civo.com/docs)
  - [OCI CLI](https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/cli.htm)
  - [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html)
  - [gcloud CLI](https://cloud.google.com/sdk/docs/install)
  - [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli)

### Setup Instructions

Each cloud provider has its own Terraform configuration. Follow these steps:

#### 1. Clone the Repository

```bash
git clone https://github.com/brokedba/vllm_lab.git
cd vllm_lab
```

#### 2. Initialize Terraform

Navigate to the specific cloud provider directory and initialize Terraform:

```bash
cd terraform/<provider>
terraform init
```

#### 3. Customize Variables

Update the `terraform.tfvars` file with your credentials and configuration options.

#### 4. Deploy the Cluster

```bash
terraform apply -auto-approve
```

#### 5. Deploy vLLM

Once the Kubernetes cluster is up, deploy `vLLM` using Helm:

```bash
helm repo add vllm https://vllm-project.github.io/helm-charts/
helm install vllm vllm/vllm --namespace vllm --create-namespace
```

## Structure

```
vllm-lab/
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ civo/
â”‚   â”œâ”€â”€ oci/
â”‚   â”œâ”€â”€ aws/
â”‚   â”œâ”€â”€ gcp/
â”‚   â”œâ”€â”€ azure/
â”œâ”€â”€ helm/
â”‚   â”œâ”€â”€ values.yaml
â”‚   â”œâ”€â”€ templates/
â””â”€â”€ README.md
```

## Next Steps

- Implement monitoring with Prometheus/Grafana.
- Add autoscaling configurations for vLLM.
- Improve security configurations.

## Contributions

PRs and issues are welcome! ðŸš€

